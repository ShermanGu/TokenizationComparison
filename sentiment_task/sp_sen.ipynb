{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from datasets import load_dataset, load_metric\n",
    "from transformers import (\n",
    "    PreTrainedTokenizerFast,\n",
    "    Trainer, \n",
    "    TrainingArguments, \n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    ")\n",
    "import sentencepiece as spm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "translation_dataset = load_dataset(\"wmt14\", \"de-en\", split=\"train[:1%]\")\n",
    "sentiment_dataset = load_dataset(\"amazon_polarity\", split=\"train[:1%]\")  # Just an example in English, replace with multilingual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You set `add_prefix_space`. The tokenizer needs to be converted from the slow tokenizers\n"
     ]
    }
   ],
   "source": [
    "#Phase 2: Experiments (Fine-tuning Models)\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM  # For translation tasks, e.g., MarianMT\n",
    "\n",
    "def load_custom_tokenizer(tokenizer_type=\"bpe\"):\n",
    "    if tokenizer_type == \"bpe\":\n",
    "        # Load a fast tokenizer from files\n",
    "        # This is a simplified example, in practice you'd wrap it with PreTrainedTokenizerFast\n",
    "        return AutoTokenizer.from_pretrained(\"tokenizers/bpe\", use_fast=True)\n",
    "    elif tokenizer_type == \"sp\":\n",
    "        return AutoTokenizer.from_pretrained(\"tokenizers/sp_unigram_hf\", use_fast=True)\n",
    "    elif tokenizer_type == \"wp\":\n",
    "        return AutoTokenizer.from_pretrained(\"tokenizers/wp\", use_fast=True)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported tokenizer type\")\n",
    "\n",
    "baseline_tokenizer = load_custom_tokenizer(\"sp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15b54422226048a3a968afbaa75b2e78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/28800 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f926d8fae76496f9ed336e10e25e91f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "split_dataset = sentiment_dataset.train_test_split(test_size=0.2, seed=42)\n",
    "train_dataset = split_dataset[\"train\"]\n",
    "eval_dataset = split_dataset[\"test\"]\n",
    "\n",
    "def preprocess_function_sentiment(examples):\n",
    "    texts = examples[\"content\"]\n",
    "    labels = examples[\"label\"]\n",
    "    tokenized_inputs = baseline_tokenizer(\n",
    "        texts,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=128\n",
    "    )\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs\n",
    "\n",
    "tokenized_train = train_dataset.map(preprocess_function_sentiment, batched=True)\n",
    "tokenized_eval = eval_dataset.map(preprocess_function_sentiment, batched=True)\n",
    "\n",
    "tokenized_train = tokenized_train.remove_columns([\"content\", \"label\"])\n",
    "tokenized_eval = tokenized_eval.remove_columns([\"content\", \"label\"])\n",
    "\n",
    "tokenized_train.set_format(\"torch\")\n",
    "tokenized_eval.set_format(\"torch\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# For translation tasks, you might use a MarianMT model or mBART, for sentiment XLM-R or mBERT.\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_name = \"bert-base-uncased\" \n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sg/anaconda3/lib/python3.11/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/var/folders/x8/bnjqxpd164n045xxqsqmvx9w0000gn/T/ipykernel_74383/1736486005.py:15: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metric_accuracy = load_metric(\"accuracy\")\n",
      "/Users/sg/anaconda3/lib/python3.11/site-packages/datasets/load.py:759: FutureWarning: The repository for accuracy contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.1/metrics/accuracy/accuracy.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train_args = TrainingArguments(\n",
    "    output_dir=\"checkpoints/sentiment_sp\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_dir=\"logs\",\n",
    "    num_train_epochs=10,          \n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    save_total_limit=2,\n",
    "    load_best_model_at_end=True,\n",
    "    fp16=(device.type == \"cuda\"),\n",
    "    push_to_hub=False,\n",
    ")\n",
    "\n",
    "metric_accuracy = load_metric(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/x8/bnjqxpd164n045xxqsqmvx9w0000gn/T/ipykernel_74383/1230184579.py:6: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = logits.argmax(axis=-1)\n",
    "    return metric_accuracy.compute(predictions=predictions, references=labels)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=train_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_eval,\n",
    "    tokenizer=baseline_tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57ede43421614092887af95fbf8db05c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6997, 'grad_norm': 1.7761789560317993, 'learning_rate': 4.8611111111111115e-05, 'epoch': 0.28}\n",
      "{'loss': 0.6975, 'grad_norm': 1.7528256177902222, 'learning_rate': 4.722222222222222e-05, 'epoch': 0.56}\n",
      "{'loss': 0.6958, 'grad_norm': 5.4670729637146, 'learning_rate': 4.5833333333333334e-05, 'epoch': 0.83}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a473f79103e74a21a3951130501a2f17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/450 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.697838544845581, 'eval_accuracy': 0.4915277777777778, 'eval_runtime': 239.2729, 'eval_samples_per_second': 30.091, 'eval_steps_per_second': 1.881, 'epoch': 1.0}\n",
      "{'loss': 0.6952, 'grad_norm': 1.9082987308502197, 'learning_rate': 4.4444444444444447e-05, 'epoch': 1.11}\n",
      "{'loss': 0.6981, 'grad_norm': 1.2722952365875244, 'learning_rate': 4.305555555555556e-05, 'epoch': 1.39}\n",
      "{'loss': 0.6961, 'grad_norm': 2.096461296081543, 'learning_rate': 4.166666666666667e-05, 'epoch': 1.67}\n",
      "{'loss': 0.696, 'grad_norm': 1.2440341711044312, 'learning_rate': 4.027777777777778e-05, 'epoch': 1.94}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3a8d5610d71455da0f7f1477a955669",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/450 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6950634121894836, 'eval_accuracy': 0.4915277777777778, 'eval_runtime': 223.3938, 'eval_samples_per_second': 32.23, 'eval_steps_per_second': 2.014, 'epoch': 2.0}\n",
      "{'loss': 0.6953, 'grad_norm': 2.9187896251678467, 'learning_rate': 3.888888888888889e-05, 'epoch': 2.22}\n",
      "{'loss': 0.6947, 'grad_norm': 1.654943585395813, 'learning_rate': 3.7500000000000003e-05, 'epoch': 2.5}\n",
      "{'loss': 0.6948, 'grad_norm': 1.7665257453918457, 'learning_rate': 3.611111111111111e-05, 'epoch': 2.78}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2f5208b3da743a8ac55f13960ac7532",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/450 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6930907368659973, 'eval_accuracy': 0.5084722222222222, 'eval_runtime': 242.7198, 'eval_samples_per_second': 29.664, 'eval_steps_per_second': 1.854, 'epoch': 3.0}\n",
      "{'loss': 0.6954, 'grad_norm': 1.2543911933898926, 'learning_rate': 3.472222222222222e-05, 'epoch': 3.06}\n",
      "{'loss': 0.6939, 'grad_norm': 0.9448590874671936, 'learning_rate': 3.3333333333333335e-05, 'epoch': 3.33}\n",
      "{'loss': 0.6946, 'grad_norm': 0.6667232513427734, 'learning_rate': 3.194444444444444e-05, 'epoch': 3.61}\n",
      "{'loss': 0.6948, 'grad_norm': 0.7234439849853516, 'learning_rate': 3.055555555555556e-05, 'epoch': 3.89}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c43e86c6290f4d2cb098d9eacf56b2c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/450 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6938490271568298, 'eval_accuracy': 0.5084722222222222, 'eval_runtime': 225.1059, 'eval_samples_per_second': 31.985, 'eval_steps_per_second': 1.999, 'epoch': 4.0}\n",
      "{'loss': 0.6943, 'grad_norm': 1.3128876686096191, 'learning_rate': 2.916666666666667e-05, 'epoch': 4.17}\n",
      "{'loss': 0.6952, 'grad_norm': 1.4523448944091797, 'learning_rate': 2.777777777777778e-05, 'epoch': 4.44}\n",
      "{'loss': 0.6944, 'grad_norm': 1.024256944656372, 'learning_rate': 2.6388888888888892e-05, 'epoch': 4.72}\n",
      "{'loss': 0.6945, 'grad_norm': 0.9965711832046509, 'learning_rate': 2.5e-05, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cee5740b36ae4033b4ced043c376b958",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/450 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6930047869682312, 'eval_accuracy': 0.5084722222222222, 'eval_runtime': 222.7672, 'eval_samples_per_second': 32.321, 'eval_steps_per_second': 2.02, 'epoch': 5.0}\n",
      "{'loss': 0.6945, 'grad_norm': 0.9632492065429688, 'learning_rate': 2.361111111111111e-05, 'epoch': 5.28}\n",
      "{'loss': 0.6946, 'grad_norm': 0.8889995813369751, 'learning_rate': 2.2222222222222223e-05, 'epoch': 5.56}\n",
      "{'loss': 0.6941, 'grad_norm': 1.8074257373809814, 'learning_rate': 2.0833333333333336e-05, 'epoch': 5.83}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1979a6d757f04a10a4f90a1c6e9377e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/450 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6942467093467712, 'eval_accuracy': 0.4915277777777778, 'eval_runtime': 212.3755, 'eval_samples_per_second': 33.902, 'eval_steps_per_second': 2.119, 'epoch': 6.0}\n",
      "{'loss': 0.6938, 'grad_norm': 1.536942720413208, 'learning_rate': 1.9444444444444445e-05, 'epoch': 6.11}\n",
      "{'loss': 0.6938, 'grad_norm': 1.7304617166519165, 'learning_rate': 1.8055555555555555e-05, 'epoch': 6.39}\n",
      "{'loss': 0.6946, 'grad_norm': 1.508159875869751, 'learning_rate': 1.6666666666666667e-05, 'epoch': 6.67}\n",
      "{'loss': 0.6934, 'grad_norm': 0.845543622970581, 'learning_rate': 1.527777777777778e-05, 'epoch': 6.94}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da8760f8b8a042348b1971149d2c152a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/450 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6931324601173401, 'eval_accuracy': 0.5084722222222222, 'eval_runtime': 225.0046, 'eval_samples_per_second': 31.999, 'eval_steps_per_second': 2.0, 'epoch': 7.0}\n",
      "{'loss': 0.6939, 'grad_norm': 0.7339354753494263, 'learning_rate': 1.388888888888889e-05, 'epoch': 7.22}\n",
      "{'loss': 0.6936, 'grad_norm': 0.6099230647087097, 'learning_rate': 1.25e-05, 'epoch': 7.5}\n",
      "{'loss': 0.6936, 'grad_norm': 0.5457590222358704, 'learning_rate': 1.1111111111111112e-05, 'epoch': 7.78}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8f1d3a04271468fb76c5bb26a70791f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/450 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6931387186050415, 'eval_accuracy': 0.5084722222222222, 'eval_runtime': 219.5334, 'eval_samples_per_second': 32.797, 'eval_steps_per_second': 2.05, 'epoch': 8.0}\n",
      "{'loss': 0.6937, 'grad_norm': 1.352515459060669, 'learning_rate': 9.722222222222223e-06, 'epoch': 8.06}\n",
      "{'loss': 0.6938, 'grad_norm': 1.9672133922576904, 'learning_rate': 8.333333333333334e-06, 'epoch': 8.33}\n",
      "{'loss': 0.6935, 'grad_norm': 0.9132937788963318, 'learning_rate': 6.944444444444445e-06, 'epoch': 8.61}\n",
      "{'loss': 0.6933, 'grad_norm': 1.405375361442566, 'learning_rate': 5.555555555555556e-06, 'epoch': 8.89}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2926e3f0e79042b5adc9f0c2704dddb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/450 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.693058967590332, 'eval_accuracy': 0.5084722222222222, 'eval_runtime': 236.6355, 'eval_samples_per_second': 30.427, 'eval_steps_per_second': 1.902, 'epoch': 9.0}\n",
      "{'loss': 0.694, 'grad_norm': 1.4425933361053467, 'learning_rate': 4.166666666666667e-06, 'epoch': 9.17}\n",
      "{'loss': 0.6934, 'grad_norm': 2.410526990890503, 'learning_rate': 2.777777777777778e-06, 'epoch': 9.44}\n",
      "{'loss': 0.6928, 'grad_norm': 1.5421983003616333, 'learning_rate': 1.388888888888889e-06, 'epoch': 9.72}\n",
      "{'loss': 0.6936, 'grad_norm': 1.473081350326538, 'learning_rate': 0.0, 'epoch': 10.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbbbcb60bf654105a2fcfdce4cb4df20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/450 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6930209398269653, 'eval_accuracy': 0.5084722222222222, 'eval_runtime': 118.9082, 'eval_samples_per_second': 60.551, 'eval_steps_per_second': 3.784, 'epoch': 10.0}\n",
      "{'train_runtime': 33435.6222, 'train_samples_per_second': 8.614, 'train_steps_per_second': 0.538, 'train_loss': 0.6946745435926649, 'epoch': 10.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=18000, training_loss=0.6946745435926649, metrics={'train_runtime': 33435.6222, 'train_samples_per_second': 8.614, 'train_steps_per_second': 0.538, 'total_flos': 1.894399598592e+16, 'train_loss': 0.6946745435926649, 'epoch': 10.0})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb8cc52a4ae94f30aa35de807d86393c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/450 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results: {'eval_loss': 0.6930047869682312, 'eval_accuracy': 0.5084722222222222, 'eval_runtime': 180.6422, 'eval_samples_per_second': 39.858, 'eval_steps_per_second': 2.491, 'epoch': 10.0}\n",
      "Review: I absolutely loved this product, it exceeded my expectations!\n",
      "Predicted Sentiment: Positive\n"
     ]
    }
   ],
   "source": [
    "results = trainer.evaluate()\n",
    "print(\"Evaluation Results:\", results)\n",
    "\n",
    "\n",
    "sample_text = \"I absolutely loved this product, it exceeded my expectations!\"\n",
    "encoded = baseline_tokenizer(sample_text, return_tensors=\"pt\").to(device)\n",
    "with torch.no_grad():\n",
    "    output = model(**encoded)\n",
    "    pred = output.logits.argmax(dim=-1).item()\n",
    "    sentiment = \"Positive\" if pred == 1 else \"Negative\"\n",
    "    print(f\"Review: {sample_text}\\nPredicted Sentiment: {sentiment}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
