{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from datasets import load_dataset, load_metric\n",
    "from transformers import (\n",
    "    PreTrainedTokenizerFast,\n",
    "    Trainer, \n",
    "    TrainingArguments, \n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    ")\n",
    "import sentencepiece as spm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "translation_dataset = load_dataset(\"wmt14\", \"de-en\", split=\"train[:1%]\")\n",
    "sentiment_dataset = load_dataset(\"amazon_polarity\", split=\"train[:1%]\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Phase 2: Experiments (Fine-tuning Models)\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM  # For translation tasks, e.g., MarianMT\n",
    "\n",
    "def load_custom_tokenizer(tokenizer_type=\"bpe\"):\n",
    "    if tokenizer_type == \"bpe\":\n",
    "        # Load a fast tokenizer from files\n",
    "        # This is a simplified example, in practice you'd wrap it with PreTrainedTokenizerFast\n",
    "        return AutoTokenizer.from_pretrained(\"tokenizers/bpe\", use_fast=True)\n",
    "    elif tokenizer_type == \"sp\":\n",
    "        return AutoTokenizer.from_pretrained(\"tokenizers/sp_unigram_hf\", use_fast=True)\n",
    "    elif tokenizer_type == \"wp\":\n",
    "        return AutoTokenizer.from_pretrained(\"tokenizers/wp\", use_fast=True)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported tokenizer type\")\n",
    "\n",
    "baseline_tokenizer = load_custom_tokenizer(\"wp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4312c36896354cfe8ebb95c5d343dc4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/28800 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a9d5bbb6a59439fbbc998234369e160",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "split_dataset = sentiment_dataset.train_test_split(test_size=0.2, seed=42)\n",
    "train_dataset = split_dataset[\"train\"]\n",
    "eval_dataset = split_dataset[\"test\"]\n",
    "\n",
    "def preprocess_function_sentiment(examples):\n",
    "    texts = examples[\"content\"]\n",
    "    labels = examples[\"label\"]\n",
    "    tokenized_inputs = baseline_tokenizer(\n",
    "        texts,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=128\n",
    "    )\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs\n",
    "\n",
    "tokenized_train = train_dataset.map(preprocess_function_sentiment, batched=True)\n",
    "tokenized_eval = eval_dataset.map(preprocess_function_sentiment, batched=True)\n",
    "\n",
    "tokenized_train = tokenized_train.remove_columns([\"content\", \"label\"])\n",
    "tokenized_eval = tokenized_eval.remove_columns([\"content\", \"label\"])\n",
    "\n",
    "tokenized_train.set_format(\"torch\")\n",
    "tokenized_eval.set_format(\"torch\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# For translation tasks, you might use a MarianMT model or mBART, for sentiment XLM-R or mBERT.\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_name = \"bert-base-uncased\" \n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sg/anaconda3/lib/python3.11/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/var/folders/x8/bnjqxpd164n045xxqsqmvx9w0000gn/T/ipykernel_74395/1175339046.py:15: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metric_accuracy = load_metric(\"accuracy\")\n",
      "/Users/sg/anaconda3/lib/python3.11/site-packages/datasets/load.py:759: FutureWarning: The repository for accuracy contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.1/metrics/accuracy/accuracy.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train_args = TrainingArguments(\n",
    "    output_dir=\"checkpoints/sentiment_wp\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_dir=\"logs\",\n",
    "    num_train_epochs=10,          \n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    save_total_limit=2,\n",
    "    load_best_model_at_end=True,\n",
    "    fp16=(device.type == \"cuda\"),\n",
    "    push_to_hub=False,\n",
    ")\n",
    "\n",
    "metric_accuracy = load_metric(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/x8/bnjqxpd164n045xxqsqmvx9w0000gn/T/ipykernel_74395/1230184579.py:6: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = logits.argmax(axis=-1)\n",
    "    return metric_accuracy.compute(predictions=predictions, references=labels)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=train_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_eval,\n",
    "    tokenizer=baseline_tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e912acbd09af405ea9bc92efe0c80193",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7067, 'grad_norm': 1.5463447570800781, 'learning_rate': 4.8611111111111115e-05, 'epoch': 0.28}\n",
      "{'loss': 0.7037, 'grad_norm': 2.660998821258545, 'learning_rate': 4.722222222222222e-05, 'epoch': 0.56}\n",
      "{'loss': 0.7012, 'grad_norm': 11.847258567810059, 'learning_rate': 4.5833333333333334e-05, 'epoch': 0.83}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7123c1f2eecb444188f7952157cda197",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/450 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6944168210029602, 'eval_accuracy': 0.4915277777777778, 'eval_runtime': 242.2197, 'eval_samples_per_second': 29.725, 'eval_steps_per_second': 1.858, 'epoch': 1.0}\n",
      "{'loss': 0.7003, 'grad_norm': 3.52889347076416, 'learning_rate': 4.4444444444444447e-05, 'epoch': 1.11}\n",
      "{'loss': 0.6974, 'grad_norm': 1.674487829208374, 'learning_rate': 4.305555555555556e-05, 'epoch': 1.39}\n",
      "{'loss': 0.6977, 'grad_norm': 2.19793701171875, 'learning_rate': 4.166666666666667e-05, 'epoch': 1.67}\n",
      "{'loss': 0.6961, 'grad_norm': 1.1906877756118774, 'learning_rate': 4.027777777777778e-05, 'epoch': 1.94}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f9b27fd563f43369e1a87f16bfc9f38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/450 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6962893605232239, 'eval_accuracy': 0.4915277777777778, 'eval_runtime': 224.7011, 'eval_samples_per_second': 32.043, 'eval_steps_per_second': 2.003, 'epoch': 2.0}\n",
      "{'loss': 0.6952, 'grad_norm': 3.198172092437744, 'learning_rate': 3.888888888888889e-05, 'epoch': 2.22}\n",
      "{'loss': 0.6954, 'grad_norm': 1.66465163230896, 'learning_rate': 3.7500000000000003e-05, 'epoch': 2.5}\n",
      "{'loss': 0.6951, 'grad_norm': 1.7826969623565674, 'learning_rate': 3.611111111111111e-05, 'epoch': 2.78}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5fd034bd19f4be4a9e15b712d38d5f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/450 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6931620836257935, 'eval_accuracy': 0.4915277777777778, 'eval_runtime': 233.3945, 'eval_samples_per_second': 30.849, 'eval_steps_per_second': 1.928, 'epoch': 3.0}\n",
      "{'loss': 0.6955, 'grad_norm': 1.1851756572723389, 'learning_rate': 3.472222222222222e-05, 'epoch': 3.06}\n",
      "{'loss': 0.6946, 'grad_norm': 0.9047381281852722, 'learning_rate': 3.3333333333333335e-05, 'epoch': 3.33}\n",
      "{'loss': 0.695, 'grad_norm': 0.6642925143241882, 'learning_rate': 3.194444444444444e-05, 'epoch': 3.61}\n",
      "{'loss': 0.699, 'grad_norm': 1.4564002752304077, 'learning_rate': 3.055555555555556e-05, 'epoch': 3.89}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ae5b5eb4f90496a8fa81786fd036f01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/450 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6934797763824463, 'eval_accuracy': 0.4915277777777778, 'eval_runtime': 281.4101, 'eval_samples_per_second': 25.585, 'eval_steps_per_second': 1.599, 'epoch': 4.0}\n",
      "{'loss': 0.7024, 'grad_norm': 2.4821858406066895, 'learning_rate': 2.916666666666667e-05, 'epoch': 4.17}\n",
      "{'loss': 0.7036, 'grad_norm': 3.5028090476989746, 'learning_rate': 2.777777777777778e-05, 'epoch': 4.44}\n",
      "{'loss': 0.6985, 'grad_norm': 1.4746946096420288, 'learning_rate': 2.6388888888888892e-05, 'epoch': 4.72}\n",
      "{'loss': 0.7012, 'grad_norm': 2.959958791732788, 'learning_rate': 2.5e-05, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3aaa7aae06b446728241afbd73ca2b8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/450 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6930100321769714, 'eval_accuracy': 0.5084722222222222, 'eval_runtime': 223.9019, 'eval_samples_per_second': 32.157, 'eval_steps_per_second': 2.01, 'epoch': 5.0}\n",
      "{'loss': 0.6987, 'grad_norm': 2.621695041656494, 'learning_rate': 2.361111111111111e-05, 'epoch': 5.28}\n",
      "{'loss': 0.701, 'grad_norm': 2.4576234817504883, 'learning_rate': 2.2222222222222223e-05, 'epoch': 5.56}\n",
      "{'loss': 0.6987, 'grad_norm': 5.230316162109375, 'learning_rate': 2.0833333333333336e-05, 'epoch': 5.83}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b0c530dba39472e970c498143472e87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/450 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6930035352706909, 'eval_accuracy': 0.5084722222222222, 'eval_runtime': 215.9958, 'eval_samples_per_second': 33.334, 'eval_steps_per_second': 2.083, 'epoch': 6.0}\n",
      "{'loss': 0.6962, 'grad_norm': 3.423686981201172, 'learning_rate': 1.9444444444444445e-05, 'epoch': 6.11}\n",
      "{'loss': 0.6978, 'grad_norm': 4.0530500411987305, 'learning_rate': 1.8055555555555555e-05, 'epoch': 6.39}\n",
      "{'loss': 0.6984, 'grad_norm': 5.10493803024292, 'learning_rate': 1.6666666666666667e-05, 'epoch': 6.67}\n",
      "{'loss': 0.6962, 'grad_norm': 1.4359593391418457, 'learning_rate': 1.527777777777778e-05, 'epoch': 6.94}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55a55115e89d48bbb26d21fb1262213e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/450 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6930024027824402, 'eval_accuracy': 0.5084722222222222, 'eval_runtime': 224.1352, 'eval_samples_per_second': 32.123, 'eval_steps_per_second': 2.008, 'epoch': 7.0}\n",
      "{'loss': 0.6963, 'grad_norm': 1.278152346611023, 'learning_rate': 1.388888888888889e-05, 'epoch': 7.22}\n",
      "{'loss': 0.6974, 'grad_norm': 1.5501155853271484, 'learning_rate': 1.25e-05, 'epoch': 7.5}\n",
      "{'loss': 0.6979, 'grad_norm': 1.2144404649734497, 'learning_rate': 1.1111111111111112e-05, 'epoch': 7.78}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d7e7788fc65400b8021ec0836aa02ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/450 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6930044293403625, 'eval_accuracy': 0.5084722222222222, 'eval_runtime': 218.3198, 'eval_samples_per_second': 32.979, 'eval_steps_per_second': 2.061, 'epoch': 8.0}\n",
      "{'loss': 0.6988, 'grad_norm': 3.6359405517578125, 'learning_rate': 9.722222222222223e-06, 'epoch': 8.06}\n",
      "{'loss': 0.6982, 'grad_norm': 5.77197265625, 'learning_rate': 8.333333333333334e-06, 'epoch': 8.33}\n",
      "{'loss': 0.6968, 'grad_norm': 2.116910696029663, 'learning_rate': 6.944444444444445e-06, 'epoch': 8.61}\n",
      "{'loss': 0.6962, 'grad_norm': 2.8858444690704346, 'learning_rate': 5.555555555555556e-06, 'epoch': 8.89}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0001fd827394917a4ba4d9e8823b0bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/450 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6939027309417725, 'eval_accuracy': 0.5084722222222222, 'eval_runtime': 222.1538, 'eval_samples_per_second': 32.41, 'eval_steps_per_second': 2.026, 'epoch': 9.0}\n",
      "{'loss': 0.6965, 'grad_norm': 3.3407113552093506, 'learning_rate': 4.166666666666667e-06, 'epoch': 9.17}\n",
      "{'loss': 0.6969, 'grad_norm': 4.7902960777282715, 'learning_rate': 2.777777777777778e-06, 'epoch': 9.44}\n",
      "{'loss': 0.6954, 'grad_norm': 3.3527462482452393, 'learning_rate': 1.388888888888889e-06, 'epoch': 9.72}\n",
      "{'loss': 0.6939, 'grad_norm': 3.0110442638397217, 'learning_rate': 0.0, 'epoch': 10.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a173bd5cea940e1ac880df60d137ca5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/450 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6933375597000122, 'eval_accuracy': 0.4915277777777778, 'eval_runtime': 224.1168, 'eval_samples_per_second': 32.126, 'eval_steps_per_second': 2.008, 'epoch': 10.0}\n",
      "{'train_runtime': 32603.2927, 'train_samples_per_second': 8.833, 'train_steps_per_second': 0.552, 'train_loss': 0.6980445624457465, 'epoch': 10.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=18000, training_loss=0.6980445624457465, metrics={'train_runtime': 32603.2927, 'train_samples_per_second': 8.833, 'train_steps_per_second': 0.552, 'total_flos': 1.894399598592e+16, 'train_loss': 0.6980445624457465, 'epoch': 10.0})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ed128671149496f8c9b8202945d281f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/450 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results: {'eval_loss': 0.6930024027824402, 'eval_accuracy': 0.5084722222222222, 'eval_runtime': 180.8636, 'eval_samples_per_second': 39.809, 'eval_steps_per_second': 2.488, 'epoch': 10.0}\n",
      "Review: I absolutely loved this product, it exceeded my expectations!\n",
      "Predicted Sentiment: Positive\n"
     ]
    }
   ],
   "source": [
    "results = trainer.evaluate()\n",
    "print(\"Evaluation Results:\", results)\n",
    "\n",
    "\n",
    "sample_text = \"I absolutely loved this product, it exceeded my expectations!\"\n",
    "encoded = baseline_tokenizer(sample_text, return_tensors=\"pt\").to(device)\n",
    "with torch.no_grad():\n",
    "    output = model(**encoded)\n",
    "    pred = output.logits.argmax(dim=-1).item()\n",
    "    sentiment = \"Positive\" if pred == 1 else \"Negative\"\n",
    "    print(f\"Review: {sample_text}\\nPredicted Sentiment: {sentiment}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
